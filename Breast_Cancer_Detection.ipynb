{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 9293524,
          "sourceType": "datasetVersion",
          "datasetId": 5626466
        }
      ],
      "dockerImageVersionId": 30777,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "Breast Cancer Detection ",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/housemLassoued/ML-deployment/blob/main/Breast_Cancer_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'breast-cancer-detection:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F5626466%2F9293524%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240929%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240929T103810Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D63f8ad14ed41cccbd38fab1cf46c2728461ae06cc338600daac22c49227ab354304f07b4570a463b8be443fa46a4e6f29e8161ceb3b641ab47bdcd80d957085b6253dd6ebedbd0507dea2a477839d0141566f9fae9ff9111a73f3274bbf0c6bec8a43760b1af6c23d2b98281f95637150fc1b4519e359dcd36326d8fa9182f016797694f302588b62fe7f141d4b47c4c43ed1d61fde5812e5491bf6afed2444176158f94227a7a2e2f924737b36183bf95dcbfd74c71c5b2eb476ce517ef57033579f309f75af81d40d6337510d3b420997ef1234276668b80eb0d876d009624f44d10eb7d68d700d154d88a9f104e29e368c3c15ec2411ac911cb1b5b71ebc1'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "PArTWQ_EXBCo"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "-gdDJLK6XBCw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "train_0_path='/kaggle/input/breast-cancer-detection/train/0'\n",
        "train_1_path='/kaggle/input/breast-cancer-detection/test/1'\n",
        "test_0_path='/kaggle/input/breast-cancer-detection/test/0'\n",
        "test_1_path='/kaggle/input/breast-cancer-detection/test/1'\n",
        "valid_0_path='/kaggle/input/breast-cancer-detection/valid/0'\n",
        "valid_1_path='/kaggle/input/breast-cancer-detection/valid/1'\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:54:22.688096Z",
          "iopub.execute_input": "2024-09-28T20:54:22.688636Z",
          "iopub.status.idle": "2024-09-28T20:54:22.698483Z",
          "shell.execute_reply.started": "2024-09-28T20:54:22.688601Z",
          "shell.execute_reply": "2024-09-28T20:54:22.697665Z"
        },
        "trusted": true,
        "id": "LomeOpZgXBCy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_0_files=glob.glob(train_0_path+'/*')\n",
        "train_1_files=glob.glob(train_1_path+'/*')\n",
        "test_0_files=glob.glob(test_0_path+'/*')\n",
        "test_1_files=glob.glob(test_1_path+'/*')\n",
        "valid_0_files=glob.glob(valid_0_path+'/*')\n",
        "valid_1_files=glob.glob(valid_1_path+'/*')\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:55:53.864261Z",
          "iopub.execute_input": "2024-09-28T20:55:53.864953Z",
          "iopub.status.idle": "2024-09-28T20:55:53.884643Z",
          "shell.execute_reply.started": "2024-09-28T20:55:53.864909Z",
          "shell.execute_reply": "2024-09-28T20:55:53.883762Z"
        },
        "trusted": true,
        "id": "UhBWIHlgXBCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=[]\n",
        "y_train=[]\n",
        "x_test=[]\n",
        "y_test=[]\n",
        "x_valid=[]\n",
        "y_valid=[]\n",
        "for files in train_0_files:\n",
        "    x_train.append(files)\n",
        "    y_train.append(0)\n",
        "for files in train_1_files:\n",
        "    x_train.append(files)\n",
        "    y_train.append(1)\n",
        "for files in test_0_files:\n",
        "    x_test.append(files)\n",
        "    y_test.append(0)\n",
        "for files in test_1_files:\n",
        "    x_test.append(files)\n",
        "    y_test.append(1)\n",
        "for files in valid_0_files:\n",
        "    x_valid.append(files)\n",
        "    y_valid.append(0)\n",
        "for files in valid_1_files:\n",
        "    x_valid.append(files)\n",
        "    y_valid.append(1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:55:59.527028Z",
          "iopub.execute_input": "2024-09-28T20:55:59.527851Z",
          "iopub.status.idle": "2024-09-28T20:55:59.535121Z",
          "shell.execute_reply.started": "2024-09-28T20:55:59.527811Z",
          "shell.execute_reply": "2024-09-28T20:55:59.534157Z"
        },
        "trusted": true,
        "id": "s8peUHqYXBC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(x_train))\n",
        "print(len(y_train))\n",
        "print(len(x_test))\n",
        "print(len(y_test))\n",
        "print(len(x_valid))\n",
        "print(len(y_valid))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:56:07.461514Z",
          "iopub.execute_input": "2024-09-28T20:56:07.462132Z",
          "iopub.status.idle": "2024-09-28T20:56:07.467969Z",
          "shell.execute_reply.started": "2024-09-28T20:56:07.46209Z",
          "shell.execute_reply": "2024-09-28T20:56:07.466935Z"
        },
        "trusted": true,
        "id": "cuDG1wt_XBC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_0_train=0\n",
        "num_1_train=0\n",
        "num_0_test=0\n",
        "num_1_test=0\n",
        "num_0_valid=0\n",
        "num_1_valid=0\n",
        "for label in y_train:\n",
        "    if label==0:\n",
        "        num_0_train+=1\n",
        "    else:\n",
        "        num_1_train+=1\n",
        "for label in y_test:\n",
        "    if label==0:\n",
        "        num_0_test+=1\n",
        "    else :\n",
        "        num_1_test+=1\n",
        "for label in y_valid:\n",
        "    if label==0:\n",
        "        num_0_valid+=1\n",
        "    else :\n",
        "        num_1_valid+=1\n",
        "print(num_0_train)\n",
        "print(num_1_train)\n",
        "print(num_0_test)\n",
        "print(num_1_test)\n",
        "print(num_0_valid)\n",
        "print(num_1_valid)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:56:15.174232Z",
          "iopub.execute_input": "2024-09-28T20:56:15.174657Z",
          "iopub.status.idle": "2024-09-28T20:56:15.182291Z",
          "shell.execute_reply.started": "2024-09-28T20:56:15.174616Z",
          "shell.execute_reply": "2024-09-28T20:56:15.181407Z"
        },
        "trusted": true,
        "id": "GnaTAx2RXBC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "image= cv2.imread(x_train[0])\n",
        "if image is not None:\n",
        "    print(\"Image dimensions:\", image.shape)\n",
        "    # Afficher l'image avec Matplotlib\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Masquer les axes\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur : l'image n'a pas pu être chargée.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:56:22.295993Z",
          "iopub.execute_input": "2024-09-28T20:56:22.29638Z",
          "iopub.status.idle": "2024-09-28T20:56:22.690959Z",
          "shell.execute_reply.started": "2024-09-28T20:56:22.29634Z",
          "shell.execute_reply": "2024-09-28T20:56:22.689701Z"
        },
        "trusted": true,
        "id": "RS98HhQYXBC3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_images=[]\n",
        "x_test_images=[]\n",
        "x_valid_images=[]\n",
        "import cv2\n",
        "for i in range(len(x_train)):\n",
        "    img=cv2.imread(x_train[i],cv2.IMREAD_GRAYSCALE)\n",
        "    img=cv2.resize(img,(224,224))\n",
        "    x_train_images.append(img)\n",
        "for i in range(len(x_test)):\n",
        "    img=cv2.imread(x_test[i],cv2.IMREAD_GRAYSCALE)\n",
        "    img=cv2.resize(img,(224,224))\n",
        "    x_test_images.append(img)\n",
        "for i in range(len(x_valid)):\n",
        "    img=cv2.imread(x_valid[i],cv2.IMREAD_GRAYSCALE)\n",
        "    img=cv2.resize(img,(224,224))\n",
        "    x_valid_images.append(img)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:57:21.525367Z",
          "iopub.execute_input": "2024-09-28T20:57:21.526244Z",
          "iopub.status.idle": "2024-09-28T20:57:36.591239Z",
          "shell.execute_reply.started": "2024-09-28T20:57:21.526196Z",
          "shell.execute_reply": "2024-09-28T20:57:36.590367Z"
        },
        "trusted": true,
        "id": "P1fZuZ6YXBC4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Convertir les listes en tableaux NumPy\n",
        "x_train_images_np = np.array(x_train_images)\n",
        "x_test_images_np = np.array(x_test_images)\n",
        "x_valid_images_np = np.array(x_valid_images)\n",
        "\n",
        "# Concaténer les tableaux NumPy\n",
        "data = np.concatenate((x_train_images_np, x_test_images_np, x_valid_images_np), axis=0)\n",
        "\n",
        "# Optionnel : Afficher le shape du tableau résultant\n",
        "print(f\"Shape du tableau concaténé : {data.shape}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:59:05.73041Z",
          "iopub.execute_input": "2024-09-28T20:59:05.73135Z",
          "iopub.status.idle": "2024-09-28T20:59:05.830074Z",
          "shell.execute_reply.started": "2024-09-28T20:59:05.731309Z",
          "shell.execute_reply": "2024-09-28T20:59:05.829097Z"
        },
        "trusted": true,
        "id": "MDgGmqvkXBC5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train_np = np.array(y_train)\n",
        "y_test_np = np.array(y_test)\n",
        "y_valid_np = np.array(y_valid)\n",
        "\n",
        "\n",
        "labels = np.concatenate([y_train_np, y_test_np, y_valid_np])\n",
        "\n",
        "print(f\"Shape du labels : {labels.shape}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:59:13.626402Z",
          "iopub.execute_input": "2024-09-28T20:59:13.626815Z",
          "iopub.status.idle": "2024-09-28T20:59:13.633197Z",
          "shell.execute_reply.started": "2024-09-28T20:59:13.626775Z",
          "shell.execute_reply": "2024-09-28T20:59:13.632329Z"
        },
        "trusted": true,
        "id": "fs6nBOn9XBC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "\n",
        "# Mélanger les données d'entraînement et les étiquettes\n",
        "data, labels = shuffle(data,labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:59:20.582948Z",
          "iopub.execute_input": "2024-09-28T20:59:20.583665Z",
          "iopub.status.idle": "2024-09-28T20:59:21.113316Z",
          "shell.execute_reply.started": "2024-09-28T20:59:20.583622Z",
          "shell.execute_reply": "2024-09-28T20:59:21.112487Z"
        },
        "trusted": true,
        "id": "Ypfb9YOFXBC6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "image= data[0]\n",
        "if image is not None:\n",
        "    print(\"Image dimensions:\", image.shape)\n",
        "    # Afficher l'image avec Matplotlib\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Masquer les axes\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur : l'image n'a pas pu être chargée.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:59:28.953089Z",
          "iopub.execute_input": "2024-09-28T20:59:28.9536Z",
          "iopub.status.idle": "2024-09-28T20:59:29.106674Z",
          "shell.execute_reply.started": "2024-09-28T20:59:28.95356Z",
          "shell.execute_reply": "2024-09-28T20:59:29.105484Z"
        },
        "trusted": true,
        "id": "ITfht2vmXBC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_0 = np.sum(labels == 0)\n",
        "num_1 = np.sum(labels == 1)\n",
        "print(num_0)\n",
        "print(num_1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:00:16.253662Z",
          "iopub.execute_input": "2024-09-28T21:00:16.25408Z",
          "iopub.status.idle": "2024-09-28T21:00:16.260088Z",
          "shell.execute_reply.started": "2024-09-28T21:00:16.25404Z",
          "shell.execute_reply": "2024-09-28T21:00:16.259173Z"
        },
        "trusted": true,
        "id": "FIiapGBnXBC7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(rescale=1./255,  # Normalisation\n",
        "                             rotation_range=15,\n",
        "                             width_shift_range=0.05,\n",
        "                             height_shift_range=0.05,\n",
        "                             shear_range=0.1,\n",
        "                             zoom_range=0.1,\n",
        "                             horizontal_flip=True,\n",
        "                             fill_mode='nearest')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:00:26.496881Z",
          "iopub.execute_input": "2024-09-28T21:00:26.497311Z",
          "iopub.status.idle": "2024-09-28T21:00:38.888741Z",
          "shell.execute_reply.started": "2024-09-28T21:00:26.497271Z",
          "shell.execute_reply": "2024-09-28T21:00:38.88795Z"
        },
        "trusted": true,
        "id": "5YbZ_I8mXBC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "minority_class_images = [data[i] for i in range(len(labels)) if labels[i] == 1]\n",
        "minority_class_images = np.array(minority_class_images)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:01:14.099916Z",
          "iopub.execute_input": "2024-09-28T21:01:14.100878Z",
          "iopub.status.idle": "2024-09-28T21:01:14.116213Z",
          "shell.execute_reply.started": "2024-09-28T21:01:14.100836Z",
          "shell.execute_reply": "2024-09-28T21:01:14.115247Z"
        },
        "trusted": true,
        "id": "LHbNqFwZXBC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data = []\n",
        "augmented_labels = []\n",
        "\n",
        "# Calculer le nombre d'images à générer pour équilibrer les classes\n",
        "num_augmented_images_needed = num_0 - num_1\n",
        "\n",
        "for i in range(num_augmented_images_needed):\n",
        "    # Sélectionner une image aléatoire parmi les images de la classe minoritaire\n",
        "    img = minority_class_images[i % len(minority_class_images)]\n",
        "\n",
        "    # Vérifier et ajuster la forme de l'image en fonction des canaux\n",
        "    if len(img.shape) == 2:  # Si l'image est en 2D (224, 224), ajouter un canal (grayscale)\n",
        "        img = img.reshape((1, 224, 224, 1))\n",
        "    elif len(img.shape) == 3 and img.shape[-1] != 3:  # Si c'est une image couleur avec mauvaise forme\n",
        "        img = img.reshape((1, 224, 224, 3))\n",
        "\n",
        "    # Générer une nouvelle image augmentée\n",
        "    for augmented_img in datagen.flow(img, batch_size=1):\n",
        "        augmented_data.append(augmented_img[0])  # Ajouter l'image augmentée\n",
        "        augmented_labels.append(1)  # Ajouter le label de la classe minoritaire\n",
        "        break  # On génère une seule image par itération\n",
        "\n",
        "# Convertir les listes en arrays numpy\n",
        "augmented_data = np.array(augmented_data)\n",
        "augmented_labels = np.array(augmented_labels)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:01:22.401122Z",
          "iopub.execute_input": "2024-09-28T21:01:22.401524Z",
          "iopub.status.idle": "2024-09-28T21:01:28.111169Z",
          "shell.execute_reply.started": "2024-09-28T21:01:22.401485Z",
          "shell.execute_reply": "2024-09-28T21:01:28.110366Z"
        },
        "trusted": true,
        "id": "8wLiGvw0XBC8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image= augmented_data[0]\n",
        "if image is not None:\n",
        "    print(\"Image dimensions:\", image.shape)\n",
        "    # Afficher l'image avec Matplotlib\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Masquer les axes\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur : l'image n'a pas pu être chargée.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:01:36.880711Z",
          "iopub.execute_input": "2024-09-28T21:01:36.881578Z",
          "iopub.status.idle": "2024-09-28T21:01:36.974772Z",
          "shell.execute_reply.started": "2024-09-28T21:01:36.881538Z",
          "shell.execute_reply": "2024-09-28T21:01:36.973866Z"
        },
        "trusted": true,
        "id": "luo8XSXqXBC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augmented_data = np.squeeze(augmented_data, axis=-1)  # Supprime la dernière dimension (canal)\n",
        "print(\"Original data shape:\", data[0].shape)  # (224, 224)\n",
        "print(\"Augmented data shape:\", augmented_data[0].shape)  # Cela devrait maintenant être (224, 224)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:01:45.042206Z",
          "iopub.execute_input": "2024-09-28T21:01:45.043082Z",
          "iopub.status.idle": "2024-09-28T21:01:45.048446Z",
          "shell.execute_reply.started": "2024-09-28T21:01:45.043041Z",
          "shell.execute_reply": "2024-09-28T21:01:45.047477Z"
        },
        "trusted": true,
        "id": "jvp7H3YdXBC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image= augmented_data[0]\n",
        "if image is not None:\n",
        "    print(\"Image dimensions:\", image.shape)\n",
        "    # Afficher l'image avec Matplotlib\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Masquer les axes\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur : l'image n'a pas pu être chargée.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T20:44:29.666746Z",
          "iopub.execute_input": "2024-09-28T20:44:29.667129Z",
          "iopub.status.idle": "2024-09-28T20:44:29.758543Z",
          "shell.execute_reply.started": "2024-09-28T20:44:29.667093Z",
          "shell.execute_reply": "2024-09-28T20:44:29.757582Z"
        },
        "trusted": true,
        "id": "Kgd9pHR0XBC9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_balanced = np.concatenate((data, augmented_data), axis=0)\n",
        "labels_balanced = np.concatenate((labels, augmented_labels), axis=0)\n",
        "print(\"Balanced data shape:\", data_balanced.shape)\n",
        "print(\"Balanced labels shape:\", labels_balanced.shape)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:02:00.195566Z",
          "iopub.execute_input": "2024-09-28T21:02:00.195929Z",
          "iopub.status.idle": "2024-09-28T21:02:00.451268Z",
          "shell.execute_reply.started": "2024-09-28T21:02:00.195897Z",
          "shell.execute_reply": "2024-09-28T21:02:00.45024Z"
        },
        "trusted": true,
        "id": "UXOcg4ZbXBC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_0_balanced = np.sum(labels_balanced == 0)\n",
        "num_1_balanced = np.sum(labels_balanced == 1)\n",
        "\n",
        "print(f\"Nombre d'images dans la classe 0 après équilibrage : {num_0_balanced}\")\n",
        "print(f\"Nombre d'images dans la classe 1 après équilibrage : {num_1_balanced}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:02:04.033566Z",
          "iopub.execute_input": "2024-09-28T21:02:04.03395Z",
          "iopub.status.idle": "2024-09-28T21:02:04.040094Z",
          "shell.execute_reply.started": "2024-09-28T21:02:04.033914Z",
          "shell.execute_reply": "2024-09-28T21:02:04.039079Z"
        },
        "trusted": true,
        "id": "Etv7v-xwXBC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_balanced, labels_balanced = shuffle(data_balanced,labels_balanced)\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:02:10.220604Z",
          "iopub.execute_input": "2024-09-28T21:02:10.221477Z",
          "iopub.status.idle": "2024-09-28T21:02:10.482683Z",
          "shell.execute_reply.started": "2024-09-28T21:02:10.221408Z",
          "shell.execute_reply": "2024-09-28T21:02:10.481457Z"
        },
        "trusted": true,
        "id": "oP6KOwsdXBC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "num_images = 10\n",
        "fig, axes = plt.subplots(2, 5, figsize=(15, 5))\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    if i < num_images:\n",
        "\n",
        "        ax.imshow(data_balanced[i])\n",
        "        ax.set_title(f\"Label: {labels_balanced[i]}\")\n",
        "        ax.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:02:19.887269Z",
          "iopub.execute_input": "2024-09-28T21:02:19.887654Z",
          "iopub.status.idle": "2024-09-28T21:02:20.727945Z",
          "shell.execute_reply.started": "2024-09-28T21:02:19.887619Z",
          "shell.execute_reply": "2024-09-28T21:02:20.727004Z"
        },
        "trusted": true,
        "id": "xsqhYdtZXBC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vérification des formes avant la division\n",
        "print(f\"Data balanced shape: {data_balanced.shape}\")  # (4450, 224, 224)\n",
        "print(f\"Labels balanced shape: {labels_balanced.shape}\")  # (4450,)\n",
        "\n",
        "# Si tout est correct, appliquez train_test_split\n",
        "if data_balanced.shape[0] == labels_balanced.shape[0]:\n",
        "    from sklearn.model_selection import train_test_split\n",
        "\n",
        "    # Première division : 80% pour entraînement+validation et 20% pour test\n",
        "    x_train_val, x_test, y_train_val, y_test = train_test_split(\n",
        "        data_balanced, labels_balanced,\n",
        "        test_size=0.2, random_state=42, stratify=labels_balanced\n",
        "    )\n",
        "\n",
        "    # Deuxième division : 80% pour entraînement et 20% pour validation (sur les données de train_val)\n",
        "    x_train, x_val, y_train, y_val = train_test_split(\n",
        "        x_train_val, y_train_val,\n",
        "        test_size=0.2, random_state=42, stratify=y_train_val\n",
        "    )\n",
        "\n",
        "    # Afficher les tailles des ensembles\n",
        "    print(f\"Train set: {len(x_train)} samples\")\n",
        "    print(f\"Validation set: {len(x_val)} samples\")\n",
        "    print(f\"Test set: {len(x_test)} samples\")\n",
        "else:\n",
        "    print(\"Les dimensions des données et des étiquettes sont incohérentes.\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:02:28.385261Z",
          "iopub.execute_input": "2024-09-28T21:02:28.386009Z",
          "iopub.status.idle": "2024-09-28T21:02:28.952778Z",
          "shell.execute_reply.started": "2024-09-28T21:02:28.385966Z",
          "shell.execute_reply": "2024-09-28T21:02:28.951783Z"
        },
        "trusted": true,
        "id": "dCkjsJsRXBDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.02,\n",
        "    height_shift_range=0.02,\n",
        "    zoom_range=0.01,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:03:15.465551Z",
          "iopub.execute_input": "2024-09-28T21:03:15.465935Z",
          "iopub.status.idle": "2024-09-28T21:03:15.47133Z",
          "shell.execute_reply.started": "2024-09-28T21:03:15.465899Z",
          "shell.execute_reply": "2024-09-28T21:03:15.470472Z"
        },
        "trusted": true,
        "id": "ppLBzc8NXBDA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image= x_train[0]\n",
        "if image is not None:\n",
        "    print(\"Image dimensions:\", image.shape)\n",
        "    # Afficher l'image avec Matplotlib\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Masquer les axes\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur : l'image n'a pas pu être chargée.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:03:25.8143Z",
          "iopub.execute_input": "2024-09-28T21:03:25.815043Z",
          "iopub.status.idle": "2024-09-28T21:03:25.895117Z",
          "shell.execute_reply.started": "2024-09-28T21:03:25.815Z",
          "shell.execute_reply": "2024-09-28T21:03:25.893966Z"
        },
        "trusted": true,
        "id": "q23pgdw6XBDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image= x_test[0]\n",
        "if image is not None:\n",
        "    print(\"Image dimensions:\", image.shape)\n",
        "    # Afficher l'image avec Matplotlib\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Masquer les axes\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur : l'image n'a pas pu être chargée.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:11:20.827588Z",
          "iopub.execute_input": "2024-09-28T21:11:20.828013Z",
          "iopub.status.idle": "2024-09-28T21:11:20.903001Z",
          "shell.execute_reply.started": "2024-09-28T21:11:20.827973Z",
          "shell.execute_reply": "2024-09-28T21:11:20.901952Z"
        },
        "trusted": true,
        "id": "_0z9qw6tXBDB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image= x_val[0]\n",
        "if image is not None:\n",
        "    print(\"Image dimensions:\", image.shape)\n",
        "    # Afficher l'image avec Matplotlib\n",
        "    plt.imshow(image)\n",
        "    plt.axis('off')  # Masquer les axes\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Erreur : l'image n'a pas pu être chargée.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:11:40.246006Z",
          "iopub.execute_input": "2024-09-28T21:11:40.246762Z",
          "iopub.status.idle": "2024-09-28T21:11:40.346817Z",
          "shell.execute_reply.started": "2024-09-28T21:11:40.246717Z",
          "shell.execute_reply": "2024-09-28T21:11:40.345465Z"
        },
        "trusted": true,
        "id": "3HLFFe1JXBDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Boucle pour redimensionner et s'assurer que les images ont 3 canaux\n",
        "data_processed = []\n",
        "for img in x_train:\n",
        "    # Si l'image n'a qu'une seule dimension (grayscale)\n",
        "    if len(img.shape) == 2:\n",
        "        # Convertir en image RGB en dupliquant le canal\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    elif img.shape[2] == 1:\n",
        "        # Si une image a un seul canal (grayscale dans certains cas)\n",
        "        img = np.repeat(img, 3, axis=-1)\n",
        "\n",
        "    # Redimensionner à (224, 224)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Ajouter à la liste des données traitées\n",
        "    data_processed.append(img)\n",
        "\n",
        "# Convertir la liste en array numpy (format attendu par les générateurs Keras)\n",
        "x_train_processed = np.array(data_processed)\n",
        "\n",
        "# Afficher la forme de la première image traitée\n",
        "print(\"Shape after processing:\", x_train_processed[0].shape)\n",
        "\n",
        "# Vérifier visuellement l'image\n",
        "plt.imshow(x_train_processed[0])\n",
        "plt.axis('off')  # Masquer les axes\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:12:29.051963Z",
          "iopub.execute_input": "2024-09-28T21:12:29.052875Z",
          "iopub.status.idle": "2024-09-28T21:12:30.745765Z",
          "shell.execute_reply.started": "2024-09-28T21:12:29.052835Z",
          "shell.execute_reply": "2024-09-28T21:12:30.744893Z"
        },
        "trusted": true,
        "id": "nlRRPQVDXBDC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boucle pour redimensionner et s'assurer que les images ont 3 canaux\n",
        "data_processed = []\n",
        "for img in x_test:\n",
        "    # Si l'image n'a qu'une seule dimension (grayscale)\n",
        "    if len(img.shape) == 2:\n",
        "        # Convertir en image RGB en dupliquant le canal\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    elif img.shape[2] == 1:\n",
        "        # Si une image a un seul canal (grayscale dans certains cas)\n",
        "        img = np.repeat(img, 3, axis=-1)\n",
        "\n",
        "    # Redimensionner à (224, 224)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Ajouter à la liste des données traitées\n",
        "    data_processed.append(img)\n",
        "\n",
        "# Convertir la liste en array numpy (format attendu par les générateurs Keras)\n",
        "x_test_processed = np.array(data_processed)\n",
        "\n",
        "# Afficher la forme de la première image traitée\n",
        "print(\"Shape after processing:\", x_test_processed[0].shape)\n",
        "\n",
        "# Vérifier visuellement l'image\n",
        "plt.imshow(x_test_processed[0])\n",
        "plt.axis('off')  # Masquer les axes\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:17:17.740949Z",
          "iopub.execute_input": "2024-09-28T21:17:17.741977Z",
          "iopub.status.idle": "2024-09-28T21:17:18.254175Z",
          "shell.execute_reply.started": "2024-09-28T21:17:17.741932Z",
          "shell.execute_reply": "2024-09-28T21:17:18.251387Z"
        },
        "trusted": true,
        "id": "FdH-n1W7XBDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Boucle pour redimensionner et s'assurer que les images ont 3 canaux\n",
        "data_processed = []\n",
        "for img in x_val:\n",
        "    # Si l'image n'a qu'une seule dimension (grayscale)\n",
        "    if len(img.shape) == 2:\n",
        "        # Convertir en image RGB en dupliquant le canal\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_GRAY2RGB)\n",
        "    elif img.shape[2] == 1:\n",
        "        # Si une image a un seul canal (grayscale dans certains cas)\n",
        "        img = np.repeat(img, 3, axis=-1)\n",
        "\n",
        "    # Redimensionner à (224, 224)\n",
        "    img = cv2.resize(img, (224, 224))\n",
        "\n",
        "    # Ajouter à la liste des données traitées\n",
        "    data_processed.append(img)\n",
        "\n",
        "# Convertir la liste en array numpy (format attendu par les générateurs Keras)\n",
        "x_val_processed = np.array(data_processed)\n",
        "\n",
        "# Afficher la forme de la première image traitée\n",
        "print(\"Shape after processing:\", x_val_processed[0].shape)\n",
        "\n",
        "# Vérifier visuellement l'image\n",
        "plt.imshow(x_train_processed[0])\n",
        "plt.axis('off')  # Masquer les axes\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:18:01.739723Z",
          "iopub.execute_input": "2024-09-28T21:18:01.740373Z",
          "iopub.status.idle": "2024-09-28T21:18:02.189787Z",
          "shell.execute_reply.started": "2024-09-28T21:18:01.740336Z",
          "shell.execute_reply": "2024-09-28T21:18:02.188465Z"
        },
        "trusted": true,
        "id": "dhI8WVfsXBDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow(x_train_processed, y_train, batch_size=32, shuffle=True)\n",
        "test_generator = test_val_datagen.flow(x_test_processed, y_test, batch_size=32, shuffle=False)\n",
        "validation_generator = test_val_datagen.flow(x_val_processed, y_val, batch_size=32, shuffle=False)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-28T21:18:50.591235Z",
          "iopub.execute_input": "2024-09-28T21:18:50.591628Z",
          "iopub.status.idle": "2024-09-28T21:18:50.596876Z",
          "shell.execute_reply.started": "2024-09-28T21:18:50.591593Z",
          "shell.execute_reply": "2024-09-28T21:18:50.595886Z"
        },
        "trusted": true,
        "id": "yA96_b3XXBDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D,Dropout\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "# Charger le modèle ResNet50 pré-entraîné sans les couches supérieures\n",
        "base_model =InceptionV3(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# Gel des couches de base pour éviter la mise à jour des poids pendant l'entraînement initial\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Ajouter des couches personnalisées pour la classification binaire\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)  # Réduction de la dimension\n",
        "x = Flatten()(x)  # Aplatir les sorties avant de passer à la couche dense\n",
        "x = Dense(256, activation='relu')(x) # Couche dense cachée\n",
        "x = Dropout(0.5)(x)# Dropout pour éviter le surapprentissage\n",
        "x = Dense(1, activation='sigmoid')(x)  # Couche de sortie pour la classification binaire\n",
        "\n",
        "# Créer le modèle final\n",
        "model = Model(inputs=base_model.input, outputs=x)\n",
        "\n",
        "# Compiler le modèle\n",
        "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Résumé du modèle\n",
        "model.summary()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T00:04:51.963039Z",
          "iopub.execute_input": "2024-09-29T00:04:51.963464Z",
          "iopub.status.idle": "2024-09-29T00:04:55.141193Z",
          "shell.execute_reply.started": "2024-09-29T00:04:51.963412Z",
          "shell.execute_reply": "2024-09-29T00:04:55.140293Z"
        },
        "trusted": true,
        "id": "O3Gz3d8CXBDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\n",
        "\n",
        "# Définir un callback pour l'early stopping\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
        "\n",
        "# Définir un callback pour sauvegarder le meilleur modèle\n",
        "checkpoint = ModelCheckpoint('best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
        "# Learning rate scheduler: réduire le taux d'apprentissage si l'amélioration stagne\n",
        "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=3)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T00:05:16.835175Z",
          "iopub.execute_input": "2024-09-29T00:05:16.83618Z",
          "iopub.status.idle": "2024-09-29T00:05:16.841976Z",
          "shell.execute_reply.started": "2024-09-29T00:05:16.836125Z",
          "shell.execute_reply": "2024-09-29T00:05:16.840915Z"
        },
        "trusted": true,
        "id": "bs8FxatZXBDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stop, checkpoint,reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T00:05:24.550445Z",
          "iopub.execute_input": "2024-09-29T00:05:24.550843Z",
          "iopub.status.idle": "2024-09-29T00:14:08.876357Z",
          "shell.execute_reply.started": "2024-09-29T00:05:24.550803Z",
          "shell.execute_reply": "2024-09-29T00:14:08.875479Z"
        },
        "trusted": true,
        "id": "JT2QB763XBDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Débloquer les couches profondes pour le fine-tuning\n",
        "for layer in base_model.layers[-20:]:  # On débloque les 20 dernières couches de base_model\n",
        "    layer.trainable = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T00:14:18.58813Z",
          "iopub.execute_input": "2024-09-29T00:14:18.588813Z",
          "iopub.status.idle": "2024-09-29T00:14:18.594374Z",
          "shell.execute_reply.started": "2024-09-29T00:14:18.588772Z",
          "shell.execute_reply": "2024-09-29T00:14:18.593302Z"
        },
        "trusted": true,
        "id": "NgjeS7B-XBDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Recompiler le modèle avec un taux d'apprentissage plus faible\n",
        "model.compile(optimizer=Adam(learning_rate=1e-5), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Reprendre l'entraînement avec fine-tuning\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=validation_generator,\n",
        "    epochs=50,\n",
        "    callbacks=[early_stop, checkpoint,reduce_lr]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T00:14:26.616636Z",
          "iopub.execute_input": "2024-09-29T00:14:26.617456Z",
          "iopub.status.idle": "2024-09-29T00:17:49.543198Z",
          "shell.execute_reply.started": "2024-09-29T00:14:26.617402Z",
          "shell.execute_reply": "2024-09-29T00:17:49.54241Z"
        },
        "trusted": true,
        "id": "Lir5UsP6XBDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the model\n",
        "model = load_model('/kaggle/working/best_model.keras')\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "accuracy = model.evaluate(test_generator)[1]\n",
        "\n",
        "# Print the test accuracy\n",
        "print(f\"Test Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T00:17:59.826573Z",
          "iopub.execute_input": "2024-09-29T00:17:59.827293Z",
          "iopub.status.idle": "2024-09-29T00:18:21.543816Z",
          "shell.execute_reply.started": "2024-09-29T00:17:59.827251Z",
          "shell.execute_reply": "2024-09-29T00:18:21.542926Z"
        },
        "trusted": true,
        "id": "fZimzi6aXBDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "y_pred = model.predict(test_generator)\n",
        "y_pred = np.round(y_pred).astype(int)  # Transformer les probabilités en classes 0 ou 1\n",
        "\n",
        "# Utiliser y_test directement comme les vraies étiquettes\n",
        "y_true = y_test  # Pas besoin de test_generator.classes\n",
        "\n",
        "# ---- RAPPORT DE CLASSIFICATION ----\n",
        "print(\"Rapport de classification :\")\n",
        "print(classification_report(y_true, y_pred))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T00:18:30.919487Z",
          "iopub.execute_input": "2024-09-29T00:18:30.919917Z",
          "iopub.status.idle": "2024-09-29T00:18:41.505303Z",
          "shell.execute_reply.started": "2024-09-29T00:18:30.919866Z",
          "shell.execute_reply": "2024-09-29T00:18:41.504437Z"
        },
        "trusted": true,
        "id": "N2ryFVaPXBDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_pred)\n",
        "print(\"Matrice de confusion :\")\n",
        "print(cm)\n",
        "\n",
        "# ---- AFFICHAGE GRAPHIQUE DE LA MATRICE DE CONFUSION ----\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=['Classe 0', 'Classe 1'], yticklabels=['Classe 0', 'Classe 1'])\n",
        "plt.title('Matrice de confusion')\n",
        "plt.xlabel('Prédiction')\n",
        "plt.ylabel('Réel')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-29T00:18:50.396411Z",
          "iopub.execute_input": "2024-09-29T00:18:50.396822Z",
          "iopub.status.idle": "2024-09-29T00:18:50.520638Z",
          "shell.execute_reply.started": "2024-09-29T00:18:50.396785Z",
          "shell.execute_reply": "2024-09-29T00:18:50.519471Z"
        },
        "trusted": true,
        "id": "kEleykmfXBDO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}